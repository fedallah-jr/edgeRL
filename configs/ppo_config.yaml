# PPO-specific configuration

# Include default configuration
defaults:
  - default_config

# Algorithm configuration
algorithm:
  name: "PPO"

  # PPO hyperparameters
  hyperparameters:
    # Learning
    lr: 0.0005
    gamma: 0.99
    lambda: 0.95          # GAE lambda (mapped to lambda_ in code)

    # PPO-specific
    clip_param: 0.2
    entropy_coeff: 0.0
    vf_loss_coeff: 0.5
    vf_clip_param: 10.0   # set -1.0 to disable value clipping

    # Optimization
    train_batch_size: 2048
    sgd_minibatch_size: 256
    num_sgd_iter: 10
    grad_clip: 0.5

    # Rollouts
    rollout_fragment_length: 128

    # Model (optional)
    model:
      fcnet_hiddens: [128, 128]
      fcnet_activation: relu

# Override training configuration for PPO (optional)
training:
  num_episodes: 400
  checkpoint_freq: 100

