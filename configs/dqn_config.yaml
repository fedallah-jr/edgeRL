# DQN-specific configuration

# Include default configuration
defaults:
  - default_config

# Algorithm configuration
algorithm:
  name: "DQN"
  
  # DQN hyperparameters
  hyperparameters:
    # Learning parameters
    lr: 0.0001
    gamma: 0.99
    
    # Exploration
    exploration_config:
      type: "EpsilonGreedy"
      initial_epsilon: 1.0
      final_epsilon: 0.01
      epsilon_timesteps: 10000
    
    # Network architecture
    model:
      fcnet_hiddens: [256, 256]
      fcnet_activation: "relu"
    
    # DQN specific
    double_q: true
    dueling: true
    noisy: false
    n_step: 1
    
    # Replay buffer
    replay_buffer_config:
      type: "MultiAgentPrioritizedReplayBuffer"
      capacity: 50000
      prioritized_replay_alpha: 0.6
      prioritized_replay_beta: 0.4
      prioritized_replay_eps: 0.000001
    
    # Training parameters
    train_batch_size: 32
    training_intensity: 1
    target_network_update_freq: 500
    
    # Optimization
    adam_epsilon: 0.00000001
    grad_clip: 40

# Override training configuration for DQN
training:
  num_episodes: 400
  checkpoint_freq: 200